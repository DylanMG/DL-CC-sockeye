---
title: "Combining hierarchical models and habitat data improves assessment of data limited salmon stocks "
subtitle:  |
    | Marine and Coastal Fisheries
    | Paper analysis
author: "W.I. Atlas, D.M. Glaser, B.M. Connors, C.A. Holt, D.T. Selbie, S. Cox-Rogers, C. Carr-Harris, E. Hertz, and J.W. Moore."
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/html") })
output: 
  bookdown::html_document2:
    theme: cerulean
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
#bibliography: references.bib
#csl: "https://raw.githubusercontent.com/citation-style-language/styles/master/canadian-journal-of-fisheries-and-aquatic-sciences.csl"
link-citations: true
always_allow_html: yes
---

```{r pkg-setup, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(ggh4x) #to control facetting
library(rstan) #to interface R with Stan
library(bayesplot) #for mcmc_combo plots
library(loo) #for looic
library(patchwork) #to align multi-pane plots
library(grid) #to help patchwork with fonts
library(gsl) #for lambert_W0()
source(here("R/functions.R"))

set.seed(123)

knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      echo = FALSE,
                      fig.path = paste0(here("output/plots"), "/"))
```
# Background  
This is the analysis supporting the paper see [Supplement 1](https://dylanmg.github.io/DL-CC-sockeye/output/html/S1_get_Smax_PR.html#Age_structure) for the calculation of $S_{MAX_{PR}}$ and [Supplement 2](https://dylanmg.github.io/DL-CC-sockeye/output/html/S2_diagnostics_figs.html#Posterior_distributions) for model diagnostics.  

### Load data  
Read in the PR data and the time series of stock recruit data then join into 1 big dataframe. $S_{MAX_{PR}}$ and error estimates are calculated in [Supplement 1](https://dylanmg.github.io/DL-CC-sockeye/output/html/S1_get_Smax_PR.html#Age_structure).   
```{r load-data}
SmaxPR <- read.table(here("output/data/SmaxPRs.txt"), 
                     header = TRUE) |>
  select(population, region, water_clarity, SmaxPR, SmaxPR_SD) |>
  dplyr::rename(pop = population) #to match below

SR_data <- read.table(here("data/FinalBroodSK.txt"), 
                      header = TRUE) |>
  select(-n.data, -n.stock) |> #dump useless vars
  mutate(watershed = gsub("_lake|_lakes", "", watershed)) |>
  #fix some names so it joins
  mutate(watershed = case_when(watershed == "owekino" ~ "owikeno",
                               watershed == "portjohn" ~ "port_john",
                               watershed == "freeda_brodie" ~ "freeda_lakes",
                               TRUE ~ watershed)) |> #leave the rest alone
  mutate(logRS = log(total_rec/exp_spawn)) |> #shorten names for plotting, etc.
  dplyr::rename(pop = watershed) |>
  relocate(pop, 1) |>
  filter(pop !="end_hill") |>
  arrange(pop, year) |>
  left_join(SmaxPR, by = "pop") |> #join it to have 1 object to reference
  mutate(pop = gsub("_", "-", pop)) |> #change delimiter for use later
  na.omit() |>
  group_by(pop) |>
  mutate(exp_spawn_scaled = scale(exp_spawn))

SR_pairs <- SR_data |>
  group_by(pop, region, water_clarity, SmaxPR, SmaxPR_SD) |>
  summarise(SR_pairs = n()) |>
  distinct() |>
  pull(SR_pairs)

pop_data <- read.csv(here("output/pub_tables/S1.csv")) |>
  dplyr::rename(pop = population) |>
  mutate(pop = gsub("_", "-", pop)) |> #change delimiter for use later
  mutate(pop_index = row_number()) |>
  cbind(SR_pairs)

colnames(pop_data) <- tolower(colnames(pop_data))

rm(SmaxPR, SR_pairs)
```
  
### Plot data  
Make some plots to see the data we're working with. 

#### Raw data 
```{r SR-plots-raw}
#make helpers
max_facets <- 16
pages <- ceiling(length(unique(SR_data$pop))/max_facets)
j <- 1 #facet index helper

#make and print plots
for(i in 1:pages){
  sub_dat <- filter(SR_data, 
                    pop %in% unique(SR_data$pop)[j:(j+(max_facets-1))])
  
  p <- ggplot(sub_dat, 
              aes(exp_spawn/1000, total_rec)) +
              #aes(exp_spawn_scaled, logRS)) +
    geom_point() +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=(max_facets/4), 
                       ncol=(max_facets/4), 
                       trim_blank=FALSE,
                       scales = "free") +
    labs(title = paste0("Sockeye spawner-recruit relationship (", i, " of ", pages, ")"), 
         y = "Recruits", 
         x = "Spawners (thousands)") +
    theme_bw()
  
  print(p)
  
  j <- j + max_facets
}
```

#### Linear style 
```{r SR-plots-linear}
#make helpers
max_facets <- 16
pages <- ceiling(length(unique(SR_data$pop))/max_facets)
j <- 1 #facet index helper

#make and print plots
for(i in 1:pages){
  sub_dat <- filter(SR_data, 
                    pop %in% unique(SR_data$pop)[j:(j+(max_facets-1))])
  
  p <- ggplot(sub_dat, 
              aes(exp_spawn/1000, logRS)) +
              #aes(exp_spawn_scaled, logRS)) +
    geom_point() +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=(max_facets/4), 
                       ncol=(max_facets/4), 
                       trim_blank=FALSE,
                       scales = "free_x") +
    labs(title = paste0("Sockeye spawner-recruit relationship (", i, " of ", pages, ")"), 
         y = "ln(R/S)", 
         x = "Spawners (thousands)") +
    theme_bw()
  
  print(p)
  
  j <- j + max_facets
}
```

# Modelling  
We fit a variety of Ricker stock recruit relationships (i.e. variations of  $log(R/S) = log(\alpha) - \beta*S$) in a Bayesian framework with different priors and hierarchical structures ranging in complexity. In short, we compare different groupings of hierarchical $\alpha$ and uninformative/informative priors based on biogeoclimatic zones and photosynthetic rates. These will be fit in Stan via the `rstan` package.

Models took several forms:  
 
**1.** Independent models fit to each population with uninformative priors  
**2.** Uninformative $\beta$ priors fit to each population with uninformative hierarchical $\alpha$(s) where:  
\   \ **2a.** $\alpha$ is ungrouped and drawn from a distribution across all 69 populations OR  
\   \ **2b.** $\alpha$s categorically grouped by biogeoclimatic zone (n=3) and drawn from that group's distribution.  
**3.** Fits for each population with uninformative $\alpha$, and informative $\beta$ based on $S_{MAX_{PR}}$ estimates  
**4.** Informative, hierarchical $\alpha$(s) based on model performance in model 2 (i.e. grouped $\alpha$s or not), with informative priors on data based on $S_{MAX_{PR}}$.  

Models are checked in [Supplement 2](https://dylanmg.github.io/DL-CC-sockeye/output/html/S2_diagnostics_figs.html#Posterior_distributions) and Stan code is available in our [GitHub folder](https://github.com/DylanMG/DL-CC-sockeye/tree/main/Stan). 
```{r compile-stan-data}
logRS <- SR_data$logRS #response variable
pop <- as.numeric(as.factor(SR_data$pop)) #pop index vector
N <- length(logRS) #n observations
J <- max(pop) #n populations
K <- max(as.numeric(as.factor(SR_data$region))) #n regions
region <- as.numeric(as.factor(SR_data$region)) #region index vector
reg_pop <- SR_data |> #region-pop key for indexing
  select(pop, region) |>
  distinct() |>
  pull(region) |>
  as.factor() |>
  as.numeric()

X <- matrix(rep(0, (N*J)), 
            nrow=N, 
            ncol=J) #empty predictor matrix to populate

for(i in 1:N){
  X[i, pop[i]] <- SR_data$exp_spawn[i] #populated!
}
int_X <- ifelse(X!=0, 1,0) #binary matrix to index when to "turn on" intercept 
SmaxPR <- as.numeric(unique(SR_data$SmaxPR)) #SmaxPR prior mus
SmaxPR_SD <- SR_data |> #SmaxPR SDs
  select(pop, SmaxPR_SD) |>
  distinct() |>
  pull(SmaxPR_SD) |> #got creative because a SD repeats
  as.numeric() 

stan_data <- list(logRS=logRS,
             N=N,
             pop=pop,
             J=J,
             K=K,
             region=region, 
             reg_pop=reg_pop,
             X=X,
             int_X=int_X,
             SmaxPR=SmaxPR,
             SmaxPR_SD=SmaxPR_SD)

rm(logRS, N, pop, J, K, region, reg_pop, X, int_X, SmaxPR, SmaxPR_SD)
```

```{r fits, results= "hide"}
refit <- FALSE #toggle if you want to refit models or used the stored model fits

if("m1" %in% list.files(here("output/model_fits")) & refit == FALSE){
  m1 <- readRDS(here("output/model_fits/m1"))
} else{
  m1 <- stan(here("Stan/model1.stan"), 
             data=stan_data, 
             model_name = "m1", 
             iter = 4000)
  saveRDS(m1, file = here("output/model_fits/m1"))
}

if("m2a" %in% list.files(here("output/model_fits")) & refit == FALSE){
  m2a <- readRDS(here("output/model_fits/m2a"))
} else{
  m2a <- stan(here("Stan/model2a_uncentered.stan"), 
              data=stan_data, 
              model_name = "m2a", 
              iter = 4000)
  saveRDS(m2a, file = here("output/model_fits/m2a_uncentered"))
}

if("m2b" %in% list.files(here("output/model_fits")) & refit == FALSE){
  m2b <- readRDS(here("output/model_fits/m2b"))
} else{
  m2b <- stan(here("Stan/model2b.stan"), 
              data=stan_data, 
              model_name = "m2b", 
              iter = 4000)
  saveRDS(m2b, file = here("output/model_fits/m2b"))
}

if("m3" %in% list.files(here("output/model_fits")) & refit == FALSE){
  m3 <- readRDS(here("output/model_fits/m3"))
} else{
  m3 <- stan(here("Stan/model3.stan"), 
             data=stan_data, 
             model_name = "m3", 
             iter = 4000)
  saveRDS(m3, file = here("output/model_fits/m3"))
}

if("m4" %in% list.files(here("output/model_fits")) & refit == FALSE){
  m4 <- readRDS(here("output/model_fits/m4"))
} else{
  m4 <- stan(here("Stan/model4_reparm_new-sigs.stan"), 
             data=stan_data, 
             model_name = "m4", 
             iter = 4000)
  saveRDS(m4, file = here("output/model_fits/m4_HN"))
}
```

```{r m4 diag}
bayesAB::plotNormal(0,1)
bayesAB::plotGamma(2,3)

mcmc_combo(m4, combo = c("dens_overlay", "trace"), 
           pars = c("log_a", "sd_a_pop", "sigma"), 
           gg_theme = legend_none())
mcmc_combo(m4, combo = c("dens_overlay", "trace"), 
           pars = c("log_a_region[1]", "log_a_region[2]", "log_a_region[3]"), 
           gg_theme = legend_none()) 
fit4.summary  <- as.data.frame(rstan::summary(m4)$summary)

launch_shinystan(m4)
```

## Extract draws, get $S_{MSY}$  
After extracting draws we can look at regional productivity by model.  
```{r draws-fig-data}
models <- list(m1=m1, 
               m2a=m2a, 
               m2b=m2b, 
               m3=m3, 
               m4=m4)
#get some data for figs ready
all_draws <- get_draws(models, pop_data)
```

And also look at $S_{MSY}$ varied between the top 2 models. This is some data we'll use for figure 1.  
``` {r fig 1 data}
fig1_data <- all_draws |>
  filter(model %in% c("m2b", "m4")) |> #THIS is what you change to compare different models 
  group_by(model, pop) |>
  summarise(CV = round(sd(Smsy)/mean(Smsy), 2)) |>
  pivot_wider(names_from = model, 
              values_from = CV) |>
  mutate(perc_diff_CV = perc_diff(m2b, m4), 
         diff_CV = m2b - m4, 
         diff_CV_percentage = diff_CV*100) |>
  left_join(select(pop_data, pop, region, est_origin, water_clarity, years, sr_pairs),
            by = "pop")
```

  
```{r thinning data compile}
## Thinning exercise  
  #We'll also take different amounts of data from Meziadin, which is a heavily monitored 
  #wild population that has high #quality age and escapement data.

thin <- c(.2, .4, .6, .8, 1)

thinning_pops <- "meziadin"  #set up robustly in case one wants multiple pops

thinning_data <- vector(mode="list", length(thin)*length(thinning_pops))
n <- NULL #empty obj to populate w/ n_data by percent for plotting later
k <- 1
for(i in thinning_pops){
  for(j in thin){
    
    other_data <- SR_data |>
      filter(pop != i)
    
    thinned_data <- SR_data |>
      filter(pop==i) |>
      slice_sample(prop = j)
    
    thin_df <-  bind_rows(other_data, thinned_data) |>
      arrange(pop, year) 
  
    n_data <- thinned_data |>
      summarise(n_data = as.character(n())) |>
      mutate(pop = str_to_title(i), 
             thin = gsub(".", "-", j, fixed = TRUE))
    
    n <- rbind(n, n_data)
    
    t_logRS <- thin_df$logRS #response variable
    t_pop <- as.numeric(as.factor(thin_df$pop)) #pop index vector
    t_N <- length(t_logRS) #n observations
    t_J <- max(t_pop) #n populations
    t_K <- max(as.numeric(as.factor(thin_df$region))) #n regions
    t_region <- as.numeric(as.factor(thin_df$region)) #region index vector
    t_reg_pop <- thin_df |> #region-pop key for indexing
      select(pop, region) |>
      distinct() |>
      pull(region) |>
      as.factor() |>
      as.numeric()

    t_X <- matrix(rep(0, (t_N*t_J)), 
                nrow=t_N, 
                ncol=t_J) #empty predictor matrix to populate

    for(l in 1:t_N){
      t_X[l, t_pop[l]] <- thin_df$exp_spawn[l] #populated!
      }
    t_int_X <- ifelse(t_X!=0, 1,0) #binary matrix to index when to "turn on" intercept 
    t_SmaxPR <- as.numeric(unique(thin_df$SmaxPR)) #SmaxPR prior mus
    t_SmaxPR_SD <- thin_df |> #SmaxPR SDs
      select(pop, SmaxPR_SD) |>
      distinct() |>
      pull(SmaxPR_SD) |> #got creative because a SD repeats
      as.numeric() 

    thin_list <- list(logRS=t_logRS,
                      N=t_N,
                      pop=t_pop,
                      J=t_J,
                      K=t_K,
                      region=t_region, 
                      reg_pop=t_reg_pop,
                      X=t_X,
                      int_X=t_int_X,
                      SmaxPR=t_SmaxPR,
                      SmaxPR_SD=t_SmaxPR_SD)

      thinning_data[[k]] <- thin_list
      
      k <- k + 1
  }
}

rm(thin_df, thinned_data, n_data, other_data, thin_list, t_logRS, t_N, t_pop, t_J, t_K, 
   t_region, t_reg_pop, t_X, t_int_X, t_SmaxPR, t_SmaxPR_SD)

#model fitting----------------------------------------------------------------------------

#swap delimiter in model names so we can write it as file w/o "." in the name
thinned_models <- purrr::map(thinning_pops, ~{
  paste0(.x, "_", gsub( ".", "-", thin, fixed = TRUE))}) |>
  unlist()

j <- 1 
thinned_fits <- list()

for(i in thinned_models){
  
        if(paste0("m1_", i) %in% list.files(here("output/model_fits/thinning")) & refit == FALSE){
  m1_thin <- readRDS(here(paste0("output/model_fits/thinning/m1_", i)))
} else{
  m1_thin <- stan(file=here("Stan/model1.stan"),
                  data=thinning_data[[j]], 
             iter = 4000)
  saveRDS(m1_thin, file = here(paste0("output/model_fits/thinning/m1_", i)))
}
  
        if(paste0("m2a_", i) %in% list.files(here("output/model_fits/thinning")) & refit == FALSE){
  m2a_thin <- readRDS(here(paste0("output/model_fits/thinning/m2a_", i)))
} else{
  m2a_thin <- stan(file=here("Stan/model2a.stan"),
                  data=thinning_data[[j]], 
             iter = 4000)
  saveRDS(m2a_thin, file = here(paste0("output/model_fits/thinning/m2a_", i)))
}
  
      if(paste0("m2b_", i) %in% list.files(here("output/model_fits/thinning")) & refit == FALSE){
  m2b_thin <- readRDS(here(paste0("output/model_fits/thinning/m2b_", i)))
} else{
  m2b_thin <- stan(file=here("Stan/model2b.stan"),
                  data=thinning_data[[j]], 
             iter = 4000)
  saveRDS(m2b_thin, file = here(paste0("output/model_fits/thinning/m2b_", i)))
}
  
        if(paste0("m3_", i) %in% list.files(here("output/model_fits/thinning")) & refit == FALSE){
  m3_thin <- readRDS(here(paste0("output/model_fits/thinning/m3_", i)))
} else{
  m3_thin <- stan(file=here("Stan/model3.stan"),
                  data=thinning_data[[j]], 
             iter = 4000)
  saveRDS(m3_thin, file = here(paste0("output/model_fits/thinning/m3_", i)))
}
  
  if(paste0("m4_", i) %in% list.files(here("output/model_fits/thinning")) & refit == FALSE){
  m4_thin <- readRDS(here(paste0("output/model_fits/thinning/m4_", i)))
} else{
  m4_thin <- stan(file=here("Stan/model4.stan"),
                  data=thinning_data[[j]], 
             iter = 4000)
  saveRDS(m4_thin, file = here(paste0("output/model_fits/thinning/m4_", i)))
}
  
    thinned_fits[[j]] <- m1_thin
    thinned_fits[[j+length(thinned_models)]] <- m2a_thin #add the total # of models for each to index
    thinned_fits[[j+length(thinned_models)*2]] <- m2b_thin
    thinned_fits[[j+length(thinned_models)*3]] <- m3_thin
    thinned_fits[[j+length(thinned_models)*4]] <- m4_thin
    
    j <- j + 1

}

#get draws from thinned models------------------------------------------------------------

#computationally expensive be patient
thinned_draws <- map2(thinned_fits, 
                      c(paste0("m1_", thinned_models),
                        paste0("m2a_", thinned_models),
                        paste0("m2b_", thinned_models),
                        paste0("m3_", thinned_models), 
                        paste0("m4_", thinned_models)),  
    ~cbind(rstan:::.make_plot_data(.x, 
                                   pars = c("log_a_pop", "b_pop"))$samp, 
           model_name = rep(.y)))  |> #instead of get_draws() because of model naming issue*
 bind_rows()|>
  filter(chain == 1) |>
  mutate(pop_index = as.numeric(str_extract(parameter, "[[:digit:]]+"))) |>
  left_join(select(pop_data, pop, pop_index, region), 
            by = "pop_index") |>
  filter(pop %in% str_to_title(thinning_pops)) |> #still fluff here since pops won't match model_name
  mutate(parameter = ifelse(grepl("log_a", parameter), "log_a", "b")) |>
  tidyr::pivot_wider(names_from = parameter, 
                     values_from = value) |>
  separate(model_name, c("model", "pop_reduced", "thin"), sep = "_") |>
  filter(pop_reduced == tolower(pop)) |> #only retain fits from the pop that was reduced
  select(pop, model, thin, region, log_a, b) |>
  mutate(Smsy = (1-lambert_W0(exp(1-log_a)))/b) |>
  left_join(n, by = c("pop", "thin"))

#*model naming issue - once a stan model is compiled it retains the same name; if you loop 
  #a stan model it'll keep the name of the first time the model was compiled - annoying... 

#then get the smsy bias data--------------------------------------------------------------
m4_median <- thinned_draws |>
  filter(model == "m4", thin == 1) |>
  group_by(pop) |>
  summarise(Smsy_med = median(Smsy))

Smsy_bias <- thinned_draws |>
  left_join(m4_median, by = "pop") |>
  mutate(perc_diff_Smsy = perc_diff2(log(Smsy_med), log(Smsy)), 
         pop = factor(pop, levels = thinning_pops),
         n_data = factor(n_data, levels = unique(thinned_draws$n_data)),
         thin = gsub("-", ".", thin, fixed = TRUE))

write.csv(Smsy_bias, here("output/data/Smsy_bias.csv"))
```
# Figures  

### Figure 1  

```{r fig1, fig.width=5.62, fig.height=4.215, dpi= 300}
m1_draws <- rstan:::.make_plot_data(m1, pars = "log_a_pop")$samp %>%
  rename(m1_draw = value)

m2b_draws <- rstan:::.make_plot_data(m2b, pars = "log_a_pop")$samp %>%
  rename(m2b_draw = value)

region_helper <-cbind(parameter = unique(m2b_draws$parameter), 
                       distinct(select(SR_data, pop, region)))

log_a_draws <- left_join(m2b_draws, region_helper, by = "parameter") %>%
  left_join(., m1_draws)

sub_log_a <- filter(log_a_draws, pop %in% c("atnarko", "owikeno", "koeye", "long", 
                                            "canoona", "damdochax")) %>%
  pivot_longer(cols = c('m1_draw', 'm2b_draw'), 
               names_to= 'draw_type', values_to = 'draw') %>%
  mutate(region = ifelse(draw_type == "m1_draw", NA, region), 
         pop = str_to_title(pop))

p1 <- ggplot(log_a_draws, aes(m1_draw, group=pop)) +
  geom_density() +
  theme_classic() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(title="Single population", x= NULL, y=NULL) +
  coord_cartesian(xlim=c(0,3))

p2 <- ggplot(log_a_draws, aes(m2b_draw, group=pop, color=region)) +
  geom_density(key_glyph = "point") +
  theme_classic() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank(), 
        legend.position = "bottom") +
  scale_color_viridis_d(name = "Region", 
                       labels = c("Coastal Fjord", "Interior", "Low Coastal")) +
  labs(title = "Hierarchical", x=NULL, y=NULL) +
  coord_cartesian(xlim=c(0,3))

p3 <- ggplot() +
  geom_density(data = filter(sub_log_a, draw_type == "m2b_draw"),
               aes(draw, group=draw_type, color=region)) +
  geom_density(data = filter(sub_log_a, draw_type == "m1_draw"), 
               aes(draw, group=draw_type), color="black") + 
  facet_grid(pop~.) +
  theme_classic() +
  theme(strip.text.y = element_text(size = 5), #shrink facet text
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  scale_color_viridis_d() +
  guides(color="none") + 
  labs(x = NULL, y = NULL)

#hack to get the legend shared, centered, horiziontal among plots. see
  #https://stackoverflow.com/questions/10032513/ggplot2-legend-to-bottom-and-horizontal
design <- " 
1133
1133
1133
1133
1133
2233
2233
2233
2233
2233
4444
"  
p <- p1+ p2 + p3 +
  guide_area()+ plot_layout(design=design, guides = "collect") 

print(p)

ggsave(here("output/pub_figs/fig1.png"), 
       plot = p,
       width = 5.61, 
       height = 4.22, 
       dpi = 300)
```

### Figure 2   

```{r fig2 wrangle}
index_df <- cbind(pop_data$pop, as.numeric(as.factor(pop_data$pop))) #helper df for the loop 

lakes <- c("Babine", "Long", "Meziadin", "Owikeno", "Asitika", "Bear", "Bowser", "Morice")

fig2_preds <- NULL
fig2_data <- NULL

for(i in unique(lakes)){
  for(j in c("m1", "m4")){
    sub_draw <- filter(all_draws, pop==i, model==j)
    sub_dat <- filter(SR_data, pop==tolower(i))
    
    max_samples <- nrow(sub_draw)
    spw <- seq(0, max(sub_dat$exp_spawn), length.out = 100)
    SR_pred <- matrix(NA, 100, max_samples)
    
    for(k in 1:max_samples){
      r <- sample(seq(1,max_samples), 1, replace=TRUE)
      log_a <- sub_draw$log_a[r]
      b <- sub_draw$b[r]
      SR_pred[,k] <- (exp(log_a)*spw*exp(-b*spw))
    }
    SR_pred <- cbind(spw,t(apply(SR_pred,c(1),quantile,probs=c(0.05,0.5,0.95),na.rm=T))) |>
      as.data.frame() |>
      round(2) |>
      mutate(pop = i, 
             model = j)
    
    fig2_preds <- bind_rows(SR_pred, fig2_preds)
    
    fig2_data <- bind_rows(sub_dat, fig2_data)
  }
}

colnames(fig2_preds) <- c("Spawn", "Rec_lwr", "Rec_med", "Rec_upr", "pop", "model")

fig2_preds <- fig2_preds |>
  mutate(pop = factor(pop, levels = lakes))

fig2_data <- fig2_data |>
  mutate(pop = factor(str_to_title(pop), levels = lakes))

p <- ggplot() +
  geom_ribbon(data = fig2_preds, aes(x = Spawn/1000, ymin = Rec_lwr/1000, ymax = Rec_upr/1000, 
                                      fill = model, color = model), alpha=0.5) +
  geom_line(data = fig2_preds, aes(x = Spawn/1000, y = Rec_med/1000, color=model), size = 1) +
  geom_point(data = fig2_data, aes(x=exp_spawn/1000, y=total_rec/1000)) +
  facet_wrap(~pop, scales="free", nrow=2) +
  theme_classic() +
  scale_fill_viridis_d(name = "Model", 
                       labels = c("1", "4")) +
  scale_color_viridis_d() +
  theme(text = element_text(family="serif"),
        legend.position= "bottom", 
        legend.title = element_text(size=9),
        legend.text = element_text(size=7),
        legend.key.size = unit(.5, "cm")) +
        labs(y = "Recruits (thousands)", x = "Spawners (thousands)") +
  guides(color="none")

ggsave(here("output/pub_figs/fig2.png"), 
       plot = p,
       width = 5.61, 
       height = 4.22, 
       dpi = 300)

print(p)
```

### Figure 3  
Difference in CV since CVs are standardized

```{r fig3, fig.width=5.62, fig.height=4.215, dpi= 300}
p1 <- ggplot(fig1_data,aes(sr_pairs, diff_CV)) +
  theme_classic() +
  geom_point(aes(color = region)) +
  geom_hline(yintercept = 0, 
             lty = 2) +
  annotate("text", x = 5, y = 50, label = "(A)") +
  theme(legend.position = "bottom", 
        legend.title = element_text(size = 9),
        legend.text = element_text(size = 7),
        legend.key.size = unit(.1, "cm"),
        text = element_text(family = "serif")) + 
  scale_color_viridis_d(name = "Region", 
                       labels = c("coastal fjord", "interior", "low coastal")) +
  stat_smooth(method = "loess", 
              color = "black",
              se = FALSE, 
              alpha = 0.5) +
  labs(x = "Years of SR pairs", 
       y = NULL)

p2 <- ggplot(filter(fig1_data, est_origin != "both"), aes(est_origin, diff_CV)) +
  geom_violin(aes(fill=est_origin), 
              alpha = 0.5, 
              draw_quantiles = 0.5) +
    geom_hline(yintercept = 0, 
             lty = 2) +
  annotate("text", x= .52, y = 50, label = "(B)") +
  theme_classic() +
  theme(text = element_text(family="serif"),
        legend.position= "bottom", 
        legend.title = element_text(size=9),
        legend.text = element_text(size=7),
        legend.key.size = unit(.5, "cm"),) + 
  scale_fill_viridis_d(name = "Estimate method", 
                       labels = c("empirical", "modeled")) +
  scale_x_discrete(labels = c("empirical", "modeled")) +
  labs(x= "PR estimate method", y=NULL) 

p3 <- ggplot(fig1_data, aes(region, diff_CV)) +
      geom_violin(aes(fill=est_origin), 
                  alpha = 0.5, 
                  draw_quantiles = 0.5) +
    geom_hline(yintercept = 0, 
             lty = 2) +
  annotate("text", x= .6, y = 50, label = "(C)") +
  theme_classic() +
  theme(text = element_text(family="serif")) +
  scale_fill_viridis_d() +
  scale_x_discrete(labels = c("coastal fjord", "interior", "low coastal")) +
  labs(x= "Region", y=NULL) +
  guides(fill="none")

p4 <- ggplot(fig1_data, aes(water_clarity, diff_CV)) +
  geom_violin(aes(fill=est_origin), 
              alpha = 0.5, 
              draw_quantiles = 0.5) +
  geom_hline(yintercept = 0, 
             lty = 2) +
  annotate("text", x= .6, y = 50, label = "(D)") +
  theme_classic() +
  theme(text = element_text(family="serif")) + 
  scale_fill_viridis_d() +
  labs(x= "Water clarity", y=NULL) +
  guides(fill="none")

pw <- ((p1/p3)|(p2/p4))

p <- gridExtra::grid.arrange(patchworkGrob(pw), 
                        left = textGrob(expression("Reduction in S"["MSY"]*" uncertainty (CV)"), 
                                        gp = gpar(fontfamily = "serif"), rot=90))
print(p)
#^ from https://statisticsglobe.com/add-subscript-and-superscript-to-plot-in-r example 3
ggsave(here("output/pub_figs/fig3.png"), 
       plot = p,
       width = 5.61, 
       height = 4.22, 
       dpi = 300)
```

### Figure 4  
$S_{MSY}$ posterior densities across varying amounts of data in data rich populations.  

Percent differences (i.e. bias) relative to the full data m4 median.  
```{r fig 4, fig.width=5.62, fig.height=4.215, dpi= 300}
p <- ggplot(Smsy_bias, aes(n_data, perc_diff_Smsy))+
   geom_violin(fill = "grey",
              draw_quantiles = 0.5) +
   geom_hline(yintercept = 0, 
             lty = 2) +
  facet_wrap(~model, scales = "free_y") +
  labs(title = paste("Smsy bias across different amounts of data at",
                     str_to_title(thinning_pops)), 
        y = "Percent difference", 
       x = "Numer of SR pairs") +
  theme_bw() +
  theme(legend.position = "bottom", 
        text = element_text(family="serif")) +
  guides(fill="none")

ggsave(here("output/pub_figs/fig4.png"), 
       plot = p,
       width = 5.61, 
       height = 4.22, 
       dpi = 300)

print(p)
```

### Figure ?  

```{r fig, fig.width=5.62, fig.height=4.215, dpi= 300}
p <- ggplot(filter(all_draws, model == "m1"), aes(region, log_a)) +
  geom_violin(fill = "grey",
              draw_quantiles = 0.5) +
  labs(title = "Regional Productuvity in Model 1", 
        y = "log(alpha)", 
       x = "Region") +
  theme_bw() +
  scale_x_discrete(labels = c("coastal fjord", "interior", "low coastal")) +
  theme(legend.position = "bottom", 
        text = element_text(family="serif")) 

ggsave(here("output/pub_figs/fig_unk.png"), 
       plot = p,
       width = 5.61, 
       height = 4.22, 
       dpi = 300)

print(p)
```
