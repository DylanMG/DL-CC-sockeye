---
title: "Combining hierarchical models and habitat data improves assessment of data limited salmon stocks "
subtitle:  |
    | Marine and Coastal Fisheries
    | Supplement 2: Model diagnostics and reporting full posteriors 
author: "W.I. Atlas, D.M. Glaser, B.M. Connors, C.A. Holt, D.A. Greenberg, D.T. Selbie, S. Cox-Rogers, C. Carr-Harris, E. Hertz, and J.W. Moore."
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/html") })
output: 
  bookdown::html_document2:
    theme: cerulean
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
#bibliography: references.bib
#csl: "https://raw.githubusercontent.com/citation-style-language/styles/master/canadian-journal-of-fisheries-and-aquatic-sciences.csl"
link-citations: true
always_allow_html: yes
---

```{r pkg-setup, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(ggh4x) #to control facetting
library(rstan) #to interface R with Stan
library(bayesplot) #for mcmc_combo plots
library(loo) #for looic
library(patchwork) #to align multi-pane plots
library(grid) #to help patchwork with fonts
library(gsl) #for lambert_W0()
library(DT) #for making a nice html table 
library(shinystan)
source(here("R/functions.R"))

knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      echo = FALSE,
                      scipen = 1, 
                      digits = 4)
```

```{r load fits and data}
iter <- 4000 #whatever iterations were run in analysis.Rmd, for plotting ESS
models <- c("m1", "m2a", "m2b", "m3", "m4a", "m4b")

#use map to read in all model fits as list
fits <- map(models, function(x){
  readRDS(file = here(paste0("output/model_fits/", x)))
})

SmaxPR <- read.table(here("output/data/SmaxPRs.txt"), 
                     header = TRUE) |>
  select(population, region, water_clarity, SmaxPR, SmaxPR_SD) |>
  dplyr::rename(pop = population) #to match below

SR_data <- read.table(here("data/FinalBroodSK.txt"), 
                      header = TRUE) |>
  select(-n.data, -n.stock) |> #dump useless vars
  mutate(watershed = gsub("_lake|_lakes", "", watershed)) |>
  #fix some names so it joins
  mutate(watershed = case_when(watershed == "owekino" ~ "owikeno",
                               watershed == "portjohn" ~ "port_john",
                               watershed == "freeda_brodie" ~ "freeda_lakes",
                               TRUE ~ watershed)) |> #leave the rest alone
  mutate(logRS = log(total_rec/exp_spawn)) |> #shorten names for plotting, etc.
  dplyr::rename(pop = watershed) |>
  relocate(pop, 1) |>
  filter(pop !="end_hill") |>
  arrange(pop, year) |>
  left_join(SmaxPR, by = "pop") |> #join it to have 1 object to reference
  mutate(pop = gsub("_", "-", pop)) |> #change delimiter for use later
  na.omit() #drops years missing logRS

SR_pairs <- SR_data |>
  group_by(pop, region, water_clarity, SmaxPR, SmaxPR_SD) |>
  summarise(SR_pairs = n()) |>
  distinct() |>
  pull(SR_pairs)

pop_data <- read.csv(here("output/pub_tables/S1.csv")) |>
  dplyr::rename(pop = population) |>
  mutate(pop = gsub("_", "-", pop)) |> #change delimiter for use later
  mutate(pop_index = row_number()) |>
  cbind(SR_pairs)

colnames(pop_data) <- tolower(colnames(pop_data))
```

## Diagnostics  
Diagnostics check if chains have mixed, the maximum $\hat{R}$ is less than 1.05, and that the effective sample size is at least 10% of the iterations (i.e., 800), and that iterations from posterior predictive checks look like the training data.  

In general, trace plots of MCMC samples of leading parameters appeared well mixed in all 6 models.  $\hat{R}$ were less than 1.05, with the exception of models 1 and 2b, where the maximum $\hat{R}$ were 1.09 and 1.14; large $\hat{R}$ were present in 3 of 4316 and 5 of 4324 parameters in these models, respectively.  Minimum effective sample sizes were not met in models 1, 2a and 2b. It appeared these simpler models had a difficult time estimating $\beta$ parameters. After trying various parameterizations (e.g. log transformations, centering priors), different model fitting strategies (e.g. increasing iterations, adding chains), and exploring various uninformative priors and prior structures, lower $\hat{R}$ and higher effective sample sizes were not achieved. However, posterior predictive checks showed the model returned data that fit the model reasonably well. Rather than omitting data poor populations or removing models from this paper, we kept issues with these models in mind and continued with our analysis assessing predictive performance.  

### Model 1  
Fits for each population with uninformative priors. We won't plot any `mcmc_combo()` for this because there's too many parameters (3 leading parameters per population[$\alpha$, $\beta$ and $\sigma$], since all are fit independently) to nicely visualize in a summary doc. You can fork the [code](https://github.com/DylanMG/sockeye-hab-SRR-Stan/blob/main/R/model_fitting_comparison.Rmd) and run `rstanarm::launch_shinystan()` to check chain mixtures. 
```{r m1-diag}
#mcmc_combo(fits[[1]], combo = c("dens_overlay", "trace"),  
#           pars = c("lp__"),  #turned off because just lp density
#           gg_theme = legend_none())
fit1.summary  <- as.data.frame(rstan::summary(fits[[1]])$summary)
paste("max R-hat =", max(fit1.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit1.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%") #*2 since the first half is discarded
#loo(fits[[1]])
#plot(loo(fits[[1]]))
ggplot(fit1.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) + #could annotate a "10%" here too 
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
logRS <- SR_data$logRS
model.pars1 <- rstan::extract(fits[[1]])
logRS_rep <- model.pars1$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")
```

### Model 2a  
Uninformative hierarchical $\alpha$  
```{r m2a-diag}
mcmc_combo(fits[[2]], combo = c("dens_overlay", "trace"), 
           pars = c("log_a", "sd_a_pop", "sigma", "sd_sigma_pop", "lp__"), 
           gg_theme = legend_none())
fit2a.summary  <- as.data.frame(rstan::summary(fits[[2]])$summary)
paste("max R-hat =", max(fit2a.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit2a.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%")
#loo(fits[[2]])
#plot(loo(fits[[2]]))
ggplot(fit2a.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) +
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
model.pars2a <- rstan::extract(fits[[2]])
logRS_rep <- model.pars2a$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")
```

### Model 2b  
Hierarchical $\alpha$ based on the 3 biogeoclimatic zones.    
```{r m2b-diag}
mcmc_combo(fits[[3]], combo = c("dens_overlay", "trace"), 
           pars = c("log_a",  "sd_a_pop", "sigma", "sd_sigma_pop", "lp__"), 
           gg_theme = legend_none())
mcmc_combo(fits[[3]], combo = c("dens_overlay", "trace"), 
           pars = c("z_dev_region[1]", "z_dev_region[2]", "z_dev_region[3]", "sd_a_region"), 
           gg_theme = legend_none()) 
fit2b.summary  <- as.data.frame(rstan::summary(fits[[3]])$summary)
paste("max R-hat =", max(fit2b.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit2b.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%")
#loo(fits[[3]])
#plot(loo(fits[[3]]))
ggplot(fit2b.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) +
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
model.pars2b <- rstan::extract(fits[[3]])
logRS_rep <- model.pars2b$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")
```

### Model 3  
Models fit to each lake with an informative $\beta$ prior based on $S_{Max_{PR}}$, and an uninformative prior for $\alpha$. We'll just plot the sigma here since everything else is independent. 
```{r m3-diag}
mcmc_combo(fits[[4]], combo = c("dens_overlay", "trace"), 
           pars = c("lp__"), 
           gg_theme = legend_none())
fit3.summary  <- as.data.frame(rstan::summary(fits[[4]])$summary)
paste("max R-hat =", max(fit3.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit3.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%")
#loo(fits[[4]])
#plot(loo(fits[[4]]))
ggplot(fit3.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) +
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
model.pars3 <- rstan::extract(fits[[4]])
logRS_rep <- model.pars3$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")
```

### Model 4a
Informative, hierarchical $\alpha$ with informative priors on data based on Smax_PR.   
```{r m4a-diag}
mcmc_combo(fits[[5]], combo = c("dens_overlay", "trace"), 
           pars = c("log_a",  "sd_a_pop", "sigma", "sd_sigma_pop", "lp__"), 
           gg_theme = legend_none())
fit4a.summary  <- as.data.frame(rstan::summary(fits[[5]])$summary)
paste("max R-hat =", max(fit4a.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit4a.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%")
#loo(fits[[5]])
#plot(loo(fits[[5]]))
ggplot(fit4a.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) +
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
model.pars4a <- rstan::extract(fits[[5]])
logRS_rep <- model.pars4a$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")

```

### Model 4b
Informative, regionally grouped hierarchical $\alpha$ with informative priors on data based on $S_{Max_{PR}}$.   
```{r m4b-diag}
mcmc_combo(fits[[6]], combo = c("dens_overlay", "trace"), 
           pars = c("log_a",  "sd_a_pop", "sigma", "sd_sigma_pop", "lp__"), 
           gg_theme = legend_none())
mcmc_combo(fits[[6]], combo = c("dens_overlay", "trace"), 
           pars = c("z_dev_region[1]", "z_dev_region[2]", "z_dev_region[3]", "sd_a_region"), 
           gg_theme = legend_none()) 
fit4b.summary  <- as.data.frame(rstan::summary(fits[[6]])$summary)
paste("max R-hat =", max(fit4b.summary$Rhat, na.rm = TRUE))
paste("min ESS =", round((min(fit4b.summary$n_eff, na.rm = TRUE)/iter*2)*100), "%")
#loo(fits[[6]])
#plot(loo(fits[[6]]))
ggplot(fit4b.summary, aes(n_eff)) +
  geom_histogram() +
  geom_vline(xintercept = iter*2*.1, lty=2) +
  theme_classic() +
  labs(x = "effective sample size")

#plot PPC
model.pars4b <- rstan::extract(fits[[6]])
logRS_rep <- model.pars4b$logRS_rep

ppc_dens_overlay(logRS, logRS_rep) +
  theme(legend.position = "none") +
  labs(y = "density", x = "y_est")
```

```{r get draws}
#OPTIONAL TO SHOW
#After extracting draws we can look at regional productivity by model.
#get some data for figs ready
all_draws <- get_draws(fits, pop_data)

#then get regional productivity
reg_prod <- all_draws |>
  group_by(model, region) |>
  summarise(log_a_mu = mean(log_a),
            log_a_sd = sd(log_a), 
            a_mu = round(exp(log_a_mu), 2), 
            a_sd = round(exp(log_a_sd), 2)) |>
  mutate(log_a_mu = round(log_a_mu, 2), 
         log_a_sd = round(log_a_sd, 2))

#datatable(reg_prod, rownames = FALSE, 
#          caption = NA,
#          filter = 'top', 
#          options = list(pageLength = 15, autoWidth = TRUE))
```

## Posterior distributions  

### log($\alpha$) posteriors
```{r a plots}
max_facets <- 16
pages <- ceiling(length(unique(SR_data$pop))/max_facets)

j <- 1 #facet index helper

#make and print plots
for(i in 1:pages){
  sub_dat <- filter(all_draws, 
                    pop %in% gsub("-", " ", 
                                  str_to_title(unique(SR_data$pop)))[j:(j+(max_facets-1))])
  
  p <- ggplot(sub_dat, 
              aes(model, log_a)) +
    geom_violin(fill = "grey",
                draw_quantiles = 0.5) +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=(max_facets/4), 
                       ncol=(max_facets/4), 
                       trim_blank=FALSE,
                       scales = "free_y") +
    labs(title = paste0("log(a) estimate (", i, " of ", pages, ")"), 
         y = "log_alpha", 
         x = "model") +
    theme_bw()+
  guides(fill="none")
  
  print(p)
  
  j <- j + max_facets
}
```

### $\beta$ posteriors  
```{r b plots}
j <- 1 #facet index helper

#make and print plots
for(i in 1:pages){
  sub_dat <- filter(all_draws, 
                    pop %in% gsub("-", " ", 
                                  str_to_title(unique(SR_data$pop)))[j:(j+(max_facets-1))])
  
  p <- ggplot(sub_dat, 
              aes(model, b)) +
    geom_violin(fill = "grey",
              draw_quantiles = 0.5) +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=(max_facets/4), 
                       ncol=(max_facets/4), 
                       trim_blank=FALSE,
                       scales = "free_y") +
    scale_fill_viridis_d() +
    labs(title = paste0("beta estimate (", i, " of ", pages, ")"), 
         y = "beta", 
         x = "model") +
    theme_bw()+
  guides(fill="none")
  
  print(p)
  
  j <- j + max_facets
}
```

### $S_{MSY}$ posteriors  
```{r Smsy plot}
j <- 1 #facet index helper

#make and print plots
for(i in 1:pages){
  sub_dat <- filter(all_draws, 
                    pop %in% gsub("-", " ", 
                                  str_to_title(unique(SR_data$pop)))[j:(j+(max_facets-1))])
  
  p <- ggplot(sub_dat, 
              aes(model, log(Smsy))) +
    geom_violin(fill = "grey", 
                draw_quantiles = 0.5) +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=(max_facets/4), 
                       ncol=(max_facets/4), 
                       trim_blank=FALSE,
                       scales = "free_y") +
    labs(title = paste0("Smsy estimate (", i, " of ", pages, ")"), 
         y = "log(Spawners)", 
         x = "model") +
    theme_bw() +
  guides(fill="none")
  
  print(p)
  
  j <- j + max_facets
}
```

## Models 1 and 4b fit to data

```{r m1 & m4b to data}
if(TRUE){
fig_preds <- NULL
fig_data <- NULL

for(i in unique(all_draws$pop)){
  for(j in c("m1", "m4b")){ #add or adjust the models as seen fit
    sub_draw <- filter(all_draws, pop==i, model==j)
    sub_dat <- filter(SR_data, pop==gsub(" ", "-", tolower(i)))
    
    max_samples <- nrow(sub_draw)
    spw <- seq(0, max(sub_dat$exp_spawn), length.out = 100)
    SR_pred <- matrix(NA, 100, max_samples)
    
    for(k in 1:max_samples){
      r <- sample(seq(1,max_samples), 1, replace=TRUE)
      log_a <- sub_draw$log_a[r]
      b <- sub_draw$b[r]
      SR_pred[,k] <- (exp(log_a)*spw*exp(-b*spw))
    }
    SR_pred <- cbind(spw,t(apply(SR_pred,c(1),quantile,probs=c(0.1,0.5,0.9),na.rm=T))) |>
      as.data.frame() |>
      round(2) |>
      mutate(pop = i, 
             model = j)
    
    fig_preds <- bind_rows(fig_preds, SR_pred)
    
    fig_data <- bind_rows(fig_data, sub_dat)
  }
}

colnames(fig_preds) <- c("Spawn", "Rec_lwr", "Rec_med", "Rec_upr", "pop", "model")

fig_data <- mutate(fig_data, pop = gsub("-", " ", str_to_title(pop))) 

j <- 1
max_facets <- 8

pages <- ceiling(length(unique(SR_data$pop))/max_facets)
for(i in 1:pages){
  sub_data <- filter(fig_data, 
                    pop %in% unique(fig_preds$pop)[j:(j+(max_facets-1))])

  sub_preds <- filter(fig_preds, 
                    pop %in% unique(fig_preds$pop)[j:(j+(max_facets-1))])
  
  p <- ggplot() +
    geom_ribbon(data = sub_preds, aes(x = Spawn/1000, ymin = Rec_lwr/1000, ymax = Rec_upr/1000, 
                                        fill = model, color = model), alpha=0.5) +
    geom_line(data = sub_preds, aes(x = Spawn/1000, y = Rec_med/1000, color=model), size = 1) +
    geom_point(data = sub_data, aes(x=exp_spawn/1000, y=total_rec/1000)) +
    ggh4x::facet_wrap2(vars(pop), 
                       nrow=2, 
                       ncol=4, 
                       trim_blank=FALSE, 
                       scales = "free") +
    theme_classic() +
    scale_fill_viridis_d() +
    scale_color_viridis_d() +
    theme(text = element_text(family="serif"),
          legend.position= "bottom", 
          legend.title = element_text(size=9),
          legend.text = element_text(size=7),
          legend.key.size = unit(.5, "cm")) +
        labs(title = paste0("S-R models m1 & m4b (", i, " of ", pages, ")"), 
         y = "Recruits (thousands)", 
         x = "Spawners (thousands)")

  print(p)
  j <- j + max_facets
}
}
```
